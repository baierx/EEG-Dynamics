





from numpy import pi, linspace, sin, diff, arange, asarray, zeros, exp, array, linspace, median, gradient, around
from numpy import zeros_like, triu_indices, triu_indices_from, tril_indices, var, mean, std, sqrt, where, isnan, nan_to_num, delete, floor
from numpy import nan, flip, argwhere, ones, diag, correlate, corrcoef, transpose, cov, flip, ceil, cos, sin, arctan
from numpy import angle, exp, amax, amin, absolute, meshgrid, fill_diagonal, concatenate, c_, real, argsort, tile
from numpy import empty_like, log, logical_and, copy, greater, invert, nonzero, count_nonzero, divide, repeat
from numpy import count_nonzero

from matplotlib.pyplot import xlabel, ylabel, hist, bar, yticks, legend, axis, figure, xticks, gca, show

from scipy.signal import butter, sosfilt
from scipy.stats import spearmanr, kendalltau

from matplotlib.pyplot import subplots, figure

from pandas import read_csv

import networkx as nx

from matplotlib.pyplot import subplots, xticks, yticks, axis, sca
from numpy import arange, corrcoef, fill_diagonal, zeros, linspace, argsort
from numpy import amax, gradient, array, asarray, flip, concatenate, around
from pandas import read_csv

from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC, LinearSVC
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve, roc_auc_score






def eeg_plot(data, offset, normalise=True):
    """
    Plot date columns in EEG style
    data:      two-dimensional array
    offset:    scaling factor
    normalise: normalisation of amplitudes to variance 1
    """
    from matplotlib.pyplot import subplots
    
    start = 0
    samples = data.shape[0]
    electrodes = data.shape[1]

    dataset = data[start:start+samples, :electrodes]
    means   = data[start:start+samples, :electrodes].mean(axis=0)
    devs    = data[start:start+samples, :electrodes].std(axis=0)

    fig, ax = subplots(figsize=(11, 10))

    if not normalise:
        ax.plot((dataset - means)      + offset*arange(electrodes-1,-1,-1), linewidth=1);
    else:
        ax.plot((dataset - means)/devs + offset*arange(electrodes-1,-1,-1), linewidth=1);
    
    ax.plot(zeros((samples, electrodes)) + offset*arange(electrodes-1,-1,-1),'--',color='gray');
    ax.set(ylabel='Voltage')

    yticks([]);

    axis('tight');

    return fig, ax



# read prefiltered 60 sec segment

folder      = '../Data/'
patient     = '1'         # '1'
seizure     = '01'        # '01' or '02' or '03'
series_type = 'Onset'     # 'Background' or 'Onset' 

sr_chars = folder + 'sampling_rate.txt'

df1 = read_csv(sr_chars, header=None)

sr = df1.iloc[0, 0]

series_chars = folder + 'Pat' + patient + '_Sz' + seizure + '_' + series_type + '_1_100Hz.csv'

df2 = read_csv(series_chars)
df2.head()

data_np = df2.to_numpy()
data_prefiltered = data_np[:, 1:]

all_labels = df2.columns[1:]

print('')
print(series_chars)
print('')


letter_list = list()

for new in all_labels:
    
    if new[0] not in letter_list:
        
        letter_list.append(new[0])


label_dict = dict()

for ind, letter in enumerate(all_labels):
    
    if letter[0] in label_dict.keys():
            pass

    else:
        label_dict[letter[0]] = [ind]   
        
        dict_ind = len(label_dict.keys())
        
        if letter[0] != all_labels[0][0]:
            previous_letter = letter_list[dict_ind - 2]
            label_dict[previous_letter].append(ind)
            
    if ind == len(all_labels)-1:  
        label_dict[letter[0]].append(ind+1)

label_letters = list(label_dict.keys())

label_dict



seizure


onset  = (146.7, 147.0, 146.7)



time_max = 60

init_cut  = 25

band_low  = 1
band_high = 100

order = 5

rows_max = int(time_max * sr)

sample_start = int((onset[int(seizure)-1]-30)*sr)
# sample_start = 0

sample_end = sample_start + rows_max

channel_start, channel_stop = 0, data_prefiltered.shape[1]  # Bad channels 81, 82 for 2015lvxiaofu

number_channels = channel_stop - channel_start


data_unfiltered = data_prefiltered[:, channel_start:channel_stop]


sos = butter(order, (band_low, band_high), btype='bandpass', fs=sr, output='sos')

data_filtered = zeros((rows_max, number_channels))

for index, column in enumerate(data_unfiltered.transpose()): 
    forward = sosfilt(sos, column)
    backwards = sosfilt(sos, forward[-1::-1])
    data_filtered[:, index] = backwards[-1::-1]

data_filtered.shape






stretch_factor = 5

fig, ax = eeg_plot(data_filtered, stretch_factor)

ax.set_xticks(linspace(0, rows_max, 3))
labl = linspace(sample_start//sr, sample_start//sr + time_max, 3)
ax.set_xticklabels(labl, fontsize=16)
ax.set_xlabel('Time (seconds)', fontsize=20)

ax.set_ylabel('Voltage', fontsize=20);

ax.vlines(rows_max//3,   0, stretch_factor*number_channels, color='k');
ax.vlines(2*rows_max//3, 0, stretch_factor*number_channels, color='k');

show()






data_corr_before = corrcoef(data_filtered[:1*rows_max//3, :], rowvar=False)
data_corr_after  = corrcoef(data_filtered[2*rows_max//3:, :], rowvar=False)

fill_diagonal(data_corr_before, 0)
fill_diagonal(data_corr_after,  0)

fig, ax = subplots(figsize=(10,10), ncols=2)

im = ax[0].imshow(data_corr_before, cmap='bwr', vmin=-1, vmax=1)
ax[0].set_xlabel('First Third', fontsize=14)
fig.colorbar(im, ax=ax[0], shrink=0.3, ticks=[-1., -0.5, 0, 0.5, 1.]);

im = ax[1].imshow(data_corr_after, cmap='bwr', vmin=-1, vmax=1)
fig.colorbar(im, ax=ax[1], shrink=0.3, ticks=[-1., -0.5, 0, 0.5, 1.]);
ax[1].set_xlabel('Last Third', fontsize=14);






channel_start  = 0
channel_number = 100
channels       = array(arange(channel_start, channel_start+channel_number))
channel_names  = all_labels[channel_start:channel_start+channel_number]

X_before = data_filtered[:1*rows_max//3, channels]
X_after  = data_filtered[2*rows_max//3:, channels]

X = concatenate((X_before, X_after), axis=0)

print(X.shape)






y  = zeros(X.shape[0])

y[X.shape[0]//2:] = 1

print(y.shape)






print(X[:10, 0])
print(y[:10])

print(X[-10:, 0])
print(y[-10:])









from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC, LinearSVC
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier

from sklearn.model_selection import train_test_split

RANDOM_STATE = 123

classifiers = {
    'Random Forest': RandomForestClassifier(random_state=RANDOM_STATE),
    'Extra Trees': ExtraTreesClassifier(random_state=RANDOM_STATE),
    'Decision Tree': DecisionTreeClassifier(random_state=RANDOM_STATE),
    'SVC (RBF)': SVC(random_state=RANDOM_STATE),
    'SVC (Linear)': LinearSVC(random_state=RANDOM_STATE),
    'Multi-layer Perceptron': MLPClassifier(max_iter=5000, random_state=RANDOM_STATE)
}






from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, 
                                   test_size=.5, 
                                   random_state=RANDOM_STATE, 
                                   shuffle=True)

scores = list()
name_list = list()

for name, clf in classifiers.items():
    # Training the model using training data:     
    clf.fit(X_train, y_train)

    # Predict test data
    y_pred = clf.predict(X_test)

    # Evaluating the score using test data:
    score = clf.score(X_test, y_test)
    
    # Results
    scores.append(score)
    name_list.append(name)
    print(name, score)

print('')
print('Complete')
print('')






from sklearn.metrics import roc_curve, roc_auc_score

fig, all_axes = subplots(figsize=[15, 10], ncols=3, nrows=2, sharey=True, sharex=True)

for ax, (name, clf) in zip(all_axes.ravel(), classifiers.items()):
    clf.fit(X_train, y_train)

    # Checking whether or not the object has `decision_function`:
    if hasattr(clf, 'decision_function'):
        # If it does:
        y_score = clf.decision_function(X_test)
    else:
        # Otherwise:
        y_score = clf.predict_proba(X_test)[:, 1] # only one probability is needed

    # Obtaining the x- and y-axis values for the ROC curve:
    fpr, tpr, thresh = roc_curve(y_test, y_score)

    # Obtaining the AUC value: 
    roc_auc = roc_auc_score(y_test, y_score)

    ax.plot(fpr, tpr, lw=3)
    ax.plot([0, 1], [0, 1], lw=2, linestyle='--')

    ax.set_xlabel('False Positive Rate')
    ax.set_ylabel('True Positive Rate')

    label = '{} - AUC: {:.2f}'.format(name, roc_auc)
    ax.set_title(label, fontsize=10)
    
show()









channel_start  = 0
channel_number = data_filtered.shape[1]

channels       = array(arange(channel_start, channel_start+channel_number))
channel_names  = all_labels[channel_start:channel_start+channel_number]


X_before = data_filtered[:1*rows_max//3, channels]
X_after  = data_filtered[2*rows_max//3:, channels]

X = concatenate((X_before, X_after), axis=0)

print(X.shape)


RANDOM_STATE = 111

clf_RF = RandomForestClassifier(random_state=RANDOM_STATE)

X_train, X_test, y_train, y_test = train_test_split(X, y, 
                                   test_size=.5, 
                                   random_state=RANDOM_STATE, 
                                   shuffle=True)

clf_RF.fit(X_train, y_train)









predictions_RF = clf_RF.predict(data_filtered[:, channels])

predict_RF = predictions_RF.reshape(-1, 1)

time = rows_max//sr

fig, ax = subplots(figsize=(10,1.4))

ax.imshow(predict_RF.transpose(), cmap='bwr', aspect='auto')
ax.set_xticks(linspace(0, rows_max, 4))
labl = linspace(- time/2, time/2, 4)
ax.set_xticklabels(around(labl, 1), fontsize=16)
ax.set_xlabel('Time', fontsize=14) 
ax.set_ylabel('Predictions', fontsize=14)
ax.set_yticks([])
ax.set_yticklabels([]);

show()

#fig.savefig('Long_predictions.png', format='png')





fig, ax = subplots(figsize=(10,1.4))

start, stop = 30000, 40000

ax.imshow(predict_RF[start:stop].T, cmap='bwr', aspect='auto');
ax.set_xticks(linspace(0, stop-start, 4))
labl = linspace(start//sr - time/2, stop//sr - time/2, 4)
ax.set_xticklabels(around(labl, 1), fontsize=16)

show()









probab_RF = clf_RF.predict_proba(data_filtered[:,channels])

probab_RF = probab_RF[:, 1].reshape(-1,1)

fig, ax = subplots(figsize=(10,1.4))

ax.imshow(probab_RF.transpose(), cmap='bwr', aspect='auto')
ax.set_yticks([])
ax.set_yticklabels([]);
ax.set_xticks(linspace(0, rows_max, 4))
labl = linspace(- time/2, time/2, 4)
ax.set_xticklabels(around(labl, 1), fontsize=16)
ax.set_ylabel('Probability', fontsize=12)
ax.set_yticks([])
ax.set_yticklabels([]);

fig, ax = subplots(figsize=(10,1.4))
ax.plot(probab_RF)
ax.margins(0)
ax.set_xticks(linspace(0, rows_max, 4))
labl = linspace(- time/2, time/2, 4)
ax.set_xticklabels(around(labl, 1), fontsize=16);
ax.set_xlabel('Time', fontsize=12);

show()









importances = clf_RF.feature_importances_

print('Relative feature importance:')

bins = arange(importances.shape[0])

fig, ax = subplots(figsize=(15,4))

ax.bar(bins, importances);
ax.set_xticks(bins)
ax.set_xticklabels(channel_names, rotation=-80, fontsize=10);

importance_threshold = 0.02

ax.axhline(y=importance_threshold, linewidth=1, color='m');
ax.margins(0)

show()












RF_best = importances > importance_threshold

X_best  = X[:, RF_best]

X_best.shape



RANDOM_STATE = 111

clf_RF_best = RandomForestClassifier(random_state=RANDOM_STATE)

clf_RF_best.fit(X_best, y)


predictions_RF_best = clf_RF_best.predict(data_filtered[:, RF_best])

predict_RF_best = predictions_RF_best.reshape(-1, 1)

probab_RF_best = clf_RF_best.predict_proba(data_filtered[:, RF_best])

probab_RF_best = probab_RF_best[:, 1].reshape(-1,1)



fig, ax = subplots(figsize=(10, 5), nrows=2)

ax[0].imshow(predict_RF_best.transpose(), cmap='bwr', aspect='auto')

ax[0].set_ylabel('Predictions', fontsize=12) 
ax[0].set_yticks([])
ax[0].set_yticklabels([]);
ax[0].set_xticklabels([]);

ax[1].plot(probab_RF)
ax[1].margins(0)
ax[1].set_xticks(linspace(0, rows_max, 4))
labl = linspace(- time/2, time/2, 4)
ax[1].set_xticklabels(around(labl, 1), fontsize=16);
ax[1].set_xlabel('Time', fontsize=14);

show()






importances_best = clf_RF_best.feature_importances_

channel_names_best = asarray(channel_names)[RF_best]

bins = arange(importances_best.shape[0])

fig, ax = subplots()

ax.bar(bins, importances_best);
ax.set_xticks(bins)
ax.set_xticklabels(channel_names_best, rotation=-70, fontsize=12);

# importance_threshold = 0.03
# ax.axhline(y=importance_threshold, linewidth=1, color='m');

show()









data_corr_before_sum = sum(abs(data_corr_before))
data_corr_after_sum  = sum(abs(data_corr_after))
data_corr_diff = data_corr_after_sum - data_corr_before_sum

data_corr_diff_abs = abs(data_corr_diff)

diff_indices_abs = argsort(-data_corr_diff_abs)
    
diffs_abs_ranked = data_corr_diff_abs[diff_indices_abs]

fig, ax = subplots(ncols=4, figsize=(12,4))

bins = arange(len(data_corr_before_sum))
ax[0].bar(bins, data_corr_before_sum)
ax[1].bar(bins, data_corr_after_sum)
ax[2].bar(bins, data_corr_diff_abs, color='r');
ax[3].bar(bins, diffs_abs_ranked,   color='m');

ax[0].set_xlabel('Corrs before onset')
ax[1].set_xlabel('Corrs after onset')
ax[2].set_xlabel('Differences')
ax[3].set_xlabel('Ranked differences')

fig.tight_layout()

show()



data_corr_diff_best_channels = asarray(channel_names)[diff_indices_abs[:X_best.shape[1]]]


print('Comparison of Correlation and Classification Channels')
print('')
print('Random Forest:', channel_names_best)
print('')
print('Correlations: ', list(data_corr_diff_best_channels))
print('')













